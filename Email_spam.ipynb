{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e306fc69-d71d-478a-bd39-8916b5a5f575",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\locks\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7554f31-3de5-4d01-a715-53e7df680012",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d44e88-922c-4d7e-a81c-667aa09b4b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('emails.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e71284e-d774-4ec8-9fbb-4104523767bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad424da-7317-4c82-bdcf-e6d2338d0aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='spam', data=data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8784b3-fd75-44b0-9f18-825c2edb7b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_msg = data[data.spam == 0]\n",
    "spam_msg = data[data.spam == 1]\n",
    "ham_msg = ham_msg.sample(n=len(spam_msg),\n",
    "\t\t\trandom_state=42)\n",
    "\n",
    "balanced_data = pd.concat([ham_msg, spam_msg]).reset_index(drop=True)  \n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(data = balanced_data, x='spam')\n",
    "plt.title('Distribution of Ham and Spam email messages after downsampling')\n",
    "plt.xlabel('Message types')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a15f6e8-a61b-41d7-bb25-84fdbd25e2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_data['text'] = balanced_data['text'].str.replace('Subject', '')\n",
    "balanced_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d4d516-92a5-4cf9-b715-67528620e262",
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuations_list = string.punctuation\n",
    "def remove_punctuations(text):\n",
    "\ttemp = str.maketrans('', '', punctuations_list)\n",
    "\treturn text.translate(temp)\n",
    "\n",
    "balanced_data['text']= balanced_data['text'].apply(lambda x: remove_punctuations(x))\n",
    "balanced_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397536b0-bb24-408c-95d7-69b479374dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_word_cloud(data, typ):\n",
    "\temail_corpus = \" \".join(data['text'])\n",
    "\n",
    "\tplt.figure(figsize=(7, 7))\n",
    "\n",
    "\twc = WordCloud(background_color='black',\n",
    "\t\t\t\tmax_words=100,\n",
    "\t\t\t\twidth=800,\n",
    "\t\t\t\theight=400,\n",
    "\t\t\t\tcollocations=False).generate(email_corpus)\n",
    "\n",
    "\tplt.imshow(wc, interpolation='bilinear')\n",
    "\tplt.title(f'WordCloud for {typ} emails', fontsize=15)\n",
    "\tplt.axis('off')\n",
    "\tplt.show()\n",
    "\n",
    "plot_word_cloud(balanced_data[balanced_data['spam'] == 0], typ='Non-Spam')\n",
    "plot_word_cloud(balanced_data[balanced_data['spam'] == 1], typ='Spam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e77432e-beb1-42cd-930a-c880dd5d4a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_Y, test_Y = train_test_split(balanced_data['text'],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tbalanced_data['spam'],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\ttest_size = 0.2,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\trandom_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03869276-c433-4cdf-8e07-e250ab0ff9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_X)\n",
    "\n",
    "train_sequences = tokenizer.texts_to_sequences(train_X)\n",
    "test_sequences = tokenizer.texts_to_sequences(test_X)\n",
    "\n",
    "max_len = 100 \n",
    "train_sequences = pad_sequences(train_sequences,\n",
    "\t\t\t\t\t\t\t\tmaxlen=max_len, \n",
    "\t\t\t\t\t\t\t\tpadding='post', \n",
    "\t\t\t\t\t\t\t\ttruncating='post')\n",
    "test_sequences = pad_sequences(test_sequences, \n",
    "\t\t\t\t\t\t\tmaxlen=max_len, \n",
    "\t\t\t\t\t\t\tpadding='post', \n",
    "\t\t\t\t\t\t\ttruncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79bf5b3-799d-477c-bcbe-5782eb8fc86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(input_dim=len(tokenizer.word_index) + 1,\n",
    "\t\t\t\t\t\t\t\t\toutput_dim=32, \n",
    "\t\t\t\t\t\t\t\t\tinput_length=max_len))\n",
    "model.add(tf.keras.layers.LSTM(16))\n",
    "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a8dcdb-e8d1-46d9-9374-a37ed0fb3c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = tf.keras.losses.BinaryCrossentropy(from_logits = True),\n",
    "\t\t\tmetrics = ['accuracy'],\n",
    "\t\t\toptimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de13563-5c91-49cd-a3d6-7b05bd2583fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(patience=3,\n",
    "\t\t\t\tmonitor = 'val_accuracy',\n",
    "\t\t\t\trestore_best_weights = True)\n",
    "\n",
    "lr = ReduceLROnPlateau(patience = 2,\n",
    "\t\t\t\t\tmonitor = 'val_loss',\n",
    "\t\t\t\t\tfactor = 0.5,\n",
    "\t\t\t\t\tverbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c092f8ad-5869-46c8-98ae-f5977de9d87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_sequences, train_Y,\n",
    "\t\t\t\t\tvalidation_data=(test_sequences, test_Y),\n",
    "\t\t\t\t\tepochs=20, \n",
    "\t\t\t\t\tbatch_size=32,\n",
    "\t\t\t\t\tcallbacks = [lr, es]\n",
    "\t\t\t\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087a126c-4431-4908-9ab4-23f784c74ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_sequences, test_Y)\n",
    "print('Test Loss :',test_loss)\n",
    "print('Test Accuracy :',test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a075445-dbf5-425e-884a-9797e9e371c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be20cbe1-dcb7-4e9b-805b-094bcac0e958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model.save('spam_detection_model.h5')\n",
    "\n",
    "# Save the tokenizer\n",
    "import pickle\n",
    "with open('tokenizer.pkl', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "print(\"Model and Tokenizer saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
